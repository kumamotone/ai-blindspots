
+++
title = "掘り進めるのをやめよう"
date = "2025-03-03T20:52:58-05:00"
tags = []
+++

今のLLMは、問題の途中で方向転換して「別の前提を先にやるべきだ」と気づいてタスクを中断する、ということが非常に苦手です。例えば「Xという機能を実装しよう」として着手した途中で、Yを先にやらないと無駄に手間がかかると気づいたとします。人間なら作業を中断して先にYを実装するでしょうが、LLMは指示されたタスク（X）をとにかく完遂しようと「掘り続けて」しまいます。  
ある意味、これは制御性を高める利点にもなりえます。モデルが勝手に「実際にはYが必要だから、そっちに変えます」と指示に反して動いてしまうほうが困るケースもあるからです。

結局、こうした事態を防ぐには最初から計画を立てるほうがよいという話になります。例えば、高度な推論のできるモデルで計画を立案し、それをコーディング用モデルに実行させるとか。また、Sonnetのエージェントモードではモデルがファイルを参照し計画を立てるので、ある程度は自律的に必要事項に気づいてくれる場合もあります。

理想的には、モデルが「これは無理筋だ」と判断できたらユーザに確認を仰ぐという流れがあればいいのですが、それを組み込みでやるには（コンテキストを多く消費してしまうなど）課題が残ります。別途「ウォッチドッグ的なLLM」を置いて検知させるなどのアイデアが考えられます。

## 例

- 乱数を使うモンテカルロシミュレーションの実装を変更したため、テストが不安定になりました。それらを通そうとLLM（Claude Code）に頼んだところ、確率的にテストが通らないことを理解できず、テスト側の条件をどんどん緩めて最終的にすべて通るようにする、という方向に進んでしまいました。「乱数生成をテスト時には固定シードにする」という本来の修正案にはたどり着けませんでした。

