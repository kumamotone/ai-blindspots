
[[[content/blog/_index.md]]]

+++
title = "ブログ"
+++

[[[content/blog/black-box-testing.md]]]

+++
title = "ブラックボックステスト"
date = "2025-03-03T21:18:37-05:00"
tags = []
+++

ブラックボックステストとは、コンポーネントの内部構造を知らない状態で、その機能をテストすべきだという考え方です。  
デフォルトの状態では、LLM（大規模言語モデル）はこれを遵守するのが難しくなりがちです。というのも、実装ファイルがコンテキストに含まれるか、あるいはエージェントが実装を引き出してインターフェイスの仕方を理解しようとするようにチューニングされているからです。Cursor の Sonnet 3.7 はコードを一貫性のあるものにしようと強く働きかける傾向があり、実装ファイルとテストファイルで重複している部分（本来はブラックボックステスト的に独立させたままが望ましい冗長性）を排除してしまうことがあります。

理想的には、コンテキストにファイルを読み込む際に実装をマスクしたり要約したりできるとよいでしょう。そうすることで、ブラックボックスとしてテストすべき内部実装の詳細に引きずられないようにできます。これには、アーキテクトが情報隠蔽の境界を明示的に指定する必要があります。

## 例

- Sonnet 3.7（Cursor上）に壊れているテストを修正するよう依頼したところ、必要な修正は行ったものの、ハードコーディングされていた期待値の定数を削除し、代わりに実装ファイルと同じアルゴリズムを使って計算するように書き換えてしまいました。本来テストでは定数を保持し、実装の変更がテストコードに影響しないようにしておくべきです。詳しくは[準備的リファクタリング]({{< relref "preparatory-refactoring.md" >}})を参照してください。

[[[content/blog/bulldozer-method.md]]]

+++
title = "ブルドーザー方式"
date = "2025-03-03T22:24:26-05:00"
tags = []
+++

Dan Luu が広めた [Bulldozer Method（ブルドーザー方式）](https://x.com/danluu/status/1570298241681616897) は、時に「人間離れした」成果を出すには、ただ座ってブルドーザーのように総当たり作業をし、そこから学んだことを活用して速度を上げる、というアプローチも有効だという考え方です。AIによるコーディングはまさに総当たり作業の代表例です。十分なトークン量を投下すれば、大規模なリファクタリングでも総当たりでこなせますし、逆に総当たりするためのワークフローをLLMに構築させることもできます。以前は「作業量が多すぎる」と敬遠されていた問題にもチャンスがあるかもしれません。ただし、LLMに任せきりにせず、必ずLLMが実際に何をしているかを検証しましょう。人間と違って、LLMは同じことを何度も繰り返しても飽きることがありませんし、よりよい方法を探すことをしないかもしれません。

## 例

- Rust や Haskell のような強い型付け言語でコアな関数を変更すると、関連する箇所を大量に直さなければいけない（「恐れなきリファクタリング (fearless refactoring)」と呼ばれ、型チェッカーが正しく変更箇所を特定するのに役立つ）ということがあります。通常なら「エラーを読んで修正してコンパイルする」を繰り返す必要があり面倒ですが、エージェント的に動作するLLMに任せれば、そうした修正ループを自動化できる可能性があります。

- ハードコーディングされた数字がいくつかあってテストを通すために値を更新しなければならない場合も、LLMに頼めばテストを実行しつつ必要な数値を更新し続けることができます。

[[[content/blog/culture-eats-strategy.md]]]

+++
title = "カルチャーが戦略を食べる"
date = "2025-03-12T22:56:14-04:00"
tags = []
+++

「Culture Eats Strategy (For Breakfast)」とは、どれほど優れた戦略であっても、チームのカルチャー（文化）がそれを実行できなければ意味がない、という格言です。もし問題の本質が「実行力の不足」であれば、戦略をさらに凝ったものにするより、まずはチームのカルチャーを変えることを検討すべきです。

デフォルトでは、あなたが使っているLLMは特定の「潜在空間」の一部に存在しています。コード生成をお願いすると、その出力されるスタイルは、LLMがファインチューニングされた内容や、コンテキストウィンドウ（システムプロンプトや読み込まれたファイル）に基づいて決まります。そしてこのスタイルは自己強化的に働きます。もし、コンテキストウィンドウで使われているライブラリのコードが大量にあれば、LLMは引き続きそのライブラリを使い続けようとします。逆に、そのライブラリがまったく言及されていなかったり、ファインチューニング設定でデフォルト採用されるような記述がされていなければ、LLMはそのライブラリを使わない可能性が高いです（例外はありますが、Sonnet 3.7における挙動をざっくり言えばこんな感じです）。

もしLLMがいつも好ましくないコードを書いてしまうなら、その「カルチャー」を変えてしまう必要があります。つまり、LLMを「潜在空間」の別の部分に置く必要があるということです。これにはCursor rules（プロンプト）の変更が考えられますし、既存のコードベースをリファクタリングして、自分たちが望むスタイルに統一するというアプローチもあります。LLMはコンテキスト内のトークン列を予測しようとするため、提示されるコードベース自体が「文化」になるわけです。ファインチューニングやプロンプトで制御できることもありますが、最終的には大きなコードベースのスタイルが、LLMのスタイルを支配していきます。

## 例

- Sonnet 3.7がPythonで同期コードを好む場合に、非同期コードを安定して書かせるには、既存コードの大部分をasyncに書き換える必要がありました。

[[[content/blog/keep-files-small.md]]]

+++
title = "ファイルを小さく保つ"
date = "2025-03-04T10:17:02-05:00"
tags = []
+++

コードファイルがどの程度大きいと「大きすぎる」と言えるかは、長年議論の的です。単一責任の原則に則って「クラス1つにつきファイル1つ」という人もいれば、状況によっては大きいファイルも容認できる、と考える人もいます。

しかし、RAG（Retrieval-Augmented Generation）システムがファイル単位でしかコードコンテキストを提供できないとしたら、巨大ファイルを扱うのはコンテキストを圧迫してしまいます。またCursorのようなIDEでは、LLMが生成したパッチを適用するときに失敗するケースや、仮に適用できたとしても処理が非常に遅くなる可能性があります（たとえばCursor 0.45.17では、64KBのファイルに55箇所の編集を適用するだけでもかなり時間がかかります）。さらに、128KBを超えると、Sonnet 3.7（200kトークンのコンテキストウィンドウしかない）にファイル全体の修正をさせるのは困難になります。

また、ファイルを小さく分割する作業の手間も、LLMがインポートの調整などをやってくれるのでそこまで大きくありません。

## 例

- 471KBものPythonファイルの中から、小さなテストクラスを別ファイルに移動してほしいとSonnet 3.7に依頼しました。編集自体は些細なはずでしたが、Sonnet 3.7はCursorのパッチ適用機能が正しく扱えるかたちで提案できず、結局上手くいきませんでした。

[[[content/blog/know-your-limits.md]]]

+++
title = "限界を知ろう"
date = "2025-03-12T11:43:35-04:00"
tags = []
+++

自分の手に負えないときや、必要なツールが手元にないときにはヘルプを求めるべきです。

Sonnet 3.7は自分の限界をあまり理解できません。もし「わからないことがあれば教えてほしい」とLLMに明示的に指示していなければ（たとえばSonnetのシステムプロンプトでは、ニッチな話題について質問された場合は幻覚を警告するように明示的に指示している）、LLMは知らないことでもあたかも知っているかのように回答してしまいます。特にエージェント的な利用をする場合、「LLMが実際にできないこと」を実行させようとすると、暴走して使えないコマンドを乱発してしまうおそれがあります。

## 例

- Sonnet 3.7はしきりに自分にシェルコマンドを実行する能力があると思い込んでいます。エージェントコーディングを行う際に、シェルコマンドを用意していない環境で「ファイルを実行可能にしたい」とLLMが考えると、本来やりたい操作の代わりに無関係なシェルスクリプトを作って実行しようとすることがあります。しばしば「Xをやる」と言ってツール呼び出しはYになる、といったズレが起きます。ベストな対処は、プロンプトを調整したり、LLMがやろうとしているタスクをピンポイントで実現できるツールを与えて、やりたいことを正しく実行できるようにすることです。

[[[content/blog/memento.md]]]

+++
title = "メメント"
date = "2025-03-07T20:35:24-05:00"
tags = []
+++

映画『メメント』では、主人公は新しい記憶を形成できないため、妻を殺した犯人を探すのにメモなどの手段に頼るしかありません。

この映画と同様に、使っているLLMにも「記憶」はありません。リクエストを送るたびに、そのタスクに必要なだけのコンテキスト（プロンプト、Cursor ルール、読み込まれたファイルなど）を再構築し、モデル自身がエージェントモードで必要なファイルを参照する、という動きしかできません。これがすべてです！ モデルはあなたのコードベースを、毎回ゼロから高速で「再理解」しているのです。

「熊が上手に踊ることに驚くのではない。熊が踊れること自体が驚きなのだ」という言葉がありますが、LLMが毎回コードベースを再度理解しようとするのは確かにすごいことです。ただ、その挙動はとても脆く、もしコンテキストに必要なファイルがなかったり情報が不足していれば、誤った理解をもとに作業を進めてしまい、大惨事につながる可能性もあります。

モデルに正しい行動をとってほしいなら、ドキュメントを整備し、それを参照可能にする（プロンプト経由でもよいし、モデルが期待する場所に置くのでもよい）などの工夫が必要です。大きな変更を依頼する場合は、その前に「プロジェクト全体の整合性をどう保ちたいのか」というコンテキストを与え、モデルが誤った理解のまま突き進まないように気をつけましょう。

## 例

- すでに存在するプロジェクトでE2Eテストを行う手法を考えてほしいとSonnet 3.7に依頼したところ、プロジェクトの目的自体が「テストのためだけ」と解釈されてしまい、リポジトリのREADMEまで全てテスト用の説明に書き換えられてしまいました。

[[[content/blog/mise-en-place.md]]]

+++
title = "ミザン・プラス"
date = "2025-03-06T22:25:53-05:00"
tags = []
+++

料理の世界で「ミザン・プラス（mise en place）」は、シフト中に必要になるすべての材料をあらかじめ整理・配置しておくことを指します。調理中に材料を探して右往左往しなくてすむようにするためです。

LLMにおけるミザン・プラスとは、タスク開始前にLLMが必要とするルールやMCP、開発環境などをあらかじめしっかり整備しておくことです。Sonnet 3.7 は壊れた環境を直すのがあまり得意ではありません。動的に変更される本番環境をLLMの「勘」に任せて修正しようとするのは、StackOverflowからコマンドをコピペして運良く動くのを祈るようなものです。大抵の場合、環境を取り返しのつかない状態にしてしまうだけです。  
ですから、LLMがテストを実行しても途中で環境が壊れて止まらないように、事前に正しく環境を整えておくことが大切です。

## 例

- `npm link` を使った結果VSCode環境が壊れ、あるローカルプロジェクトへのインポートが拾えない状態になっていました。その状態でCursorにlintやテストの修正を依頼したところ、Sonnet 3.7はこの問題の本質を掴めず、問題解決のために泥沼化しました（正解は `npm unlink` をすることだった）。

[[[content/blog/preparatory-refactoring.md]]]

+++
title = "準備的リファクタリング"
date = "2025-03-03T21:24:52-05:00"
tags = []
+++

[Preparatory Refactoring](https://martinfowler.com/articles/preparatory-refactoring-example.html)（準備的リファクタリング）とは、「変更を容易にするためにまずリファクタリングを行い、その後で本命の変更を行う」という手法です。リファクタリングはコードの意味を変えないため、その結果を評価しやすいというメリットがあります。

現在のLLMは、明示的な指示がないと「まずリファクタリングをしてから次のステップへ進む」といった段階的アプローチを自主的に取ってくれるわけではありません。何も言わなければ一度にすべてをやろうとします。また、LLMはしばしば「熱心すぎる新人エンジニア」のように関連性の薄い箇所までどんどん手を入れ、「ボーイスカウト原則（少しでも綺麗にしてから去れ）」を過度に実践しようとすることがあります。レビューの観点では、リファクタリングと本質的変更を同時に行われると、どこが何のための変更か把握しづらくなります。  
そこで、LLMには不要なリファクタリングをしないよう強く指示する（ただしCursor Sonnet 3.7は指示の遵守がそこまで得意ではありませんが）か、もしくはLLMが着手すると見込まれるコードを先にこちらでリファクタリングしておき、後から本命の変更を行わせる、といった運用が考えられます。また「常に型アノテーションを付けろ」といった形でLLMを指導している場合、それが余計なリファクタリングを誘発する場合もあります。LLMにどの範囲のコードを触らせるかを明確化すると改善するかもしれません。

## 例

- インポートエラーを修正してほしいとLLMに依頼したところ、インポート修正だけでなく、未アノテーションのラムダに型をつけるなど関係のないリファクタリングも勝手に行い、しかもその型アノテーションに誤りがあり、以後エージェントループが泥沼化してしまいました。

[[[content/blog/read-the-docs.md]]]

+++
title = "ドキュメントを読もう"
date = "2025-03-04T23:11:23-05:00"
tags = []
+++

新しいフレームワークやライブラリを使うとき、簡単なサンプル程度であればチュートリアルのコードをコピーして少し変えるだけでも動くでしょう。ですが、ある程度込み入った使い方をするなら、最終的には公式ドキュメントを最初から最後まで読んだほうが理解が深まり、後々役に立ちます。

AIコーディングによって、LLMはあらかじめ膨大な事前学習をもとに「人気フレームワーク」の使い方をだいたい覚えていることがあります。しかし、あまり知られていないものや学習データの範囲外にあるものについては、LLMが「幻覚」してしまうことが珍しくありません。理想的には、エージェント的なモデルがウェブ検索してドキュメントを見つけ、そこから正しく使えるようにするのが望ましいですが、Sonnet 3.7 にはウェブ検索機能がありません。したがって、必要なドキュメントページは手動でモデルに与える必要があります。CursorではURLをチャット中に貼るだけで内容を取り込めるため比較的簡単です。

## 例

- あるツールのYAML設定でPython関数を実行するように書こうとしたところ、LLMが使用法を幻覚しました。そこでマニュアルをコンテキストに渡したら、モデルは誤りを修正し、出力フォーマットもドキュメント推奨の形に合わせて修正してくれました。

[[[content/blog/requirements-not-solutions.md]]]

+++
title = "要件をまず示し、解法ではなく要件を語れ"
date = "2025-03-03T22:45:39-05:00"
tags = []
+++

人間のソフトウェアエンジニアリングでもありがちなのが、何をするべきか（要件）が明確になっていないのに、すぐに解決策を提示してしまうことです。要件が固まっていれば、その問題空間における解決策はほぼ1つに収斂するかもしれませんが、要件が曖昧だと単なる思いつきレベルの議論になりがちです。

LLMはあなたの要件を知りません。曖昧な依頼をすると、LLMは自分の学習データから最もありそうな形で細部を埋めていきます。それで問題がない場合もありますが、よりカスタムな要求があるなら、あなたが明示的に伝える必要があります。もし曖昧なまま依頼してLLMが誤解したなら、元のリクエストを修正して再度実行したほうが早いです。なぜなら、会話履歴はすべてコンテキストに残るので、一度誤解したままやり取りが続くと、その誤解を解消しにくくなるからです。

また「絶対にこの部分はこういう挙動にしてほしい」という要件があるなら、あらかじめモデルに強く伝えましょう。LLMは指示されたことを非常に忠実に実行しようとするので、きちんと要件を伝えれば期待に近づきます（もちろん、要件自体が間違っていたら悲劇ですが）。

## 例

- 「可視化するUIがほしい」とLLMに頼むと、デフォルトではSVGを生成しがちです。しかし「インタラクティブにしてほしい」と1単語加えるだけで、Reactアプリを返してくれるかもしれません。要件のちょっとした違いで解法は大きく変わります。

[[[content/blog/respect-the-spec.md]]]

+++
title = "仕様を尊重する"
date = "2025-03-07T11:28:00-05:00"
tags = []
+++

変更設計をする際は、「どの部分なら変更してよく、どの部分は変えてはいけないのか」を意識することが重要です。例えば:

- 公開APIを持っている場合、後方互換性を壊すような変更は極力避ける。
- 外部システムと連携している場合は、実際に存在するAPIの仕様に従う。勝手に自分用に都合よく書き換えてはいけない。
- テストが失敗しているからといって、テストを削除してしまうのではなく、テストの仕様が正しいかどうかを見極める。

これらはすべて、システムの一部が「仕様（spec）」になっていて、通常は勝手に変えてはいけないという例です。必要な場合に仕様を変えるのはアリですが、日常的にはまず仕様を守るほうが自然です。

LLMsは仕様を守るのがあまり得意ではありません。平気でテストを削除したりAPIを変更したりします。いくつかは常識的にNGなのでプロンプトで明示的に禁止できますが、LLMがどんな思いつきをするかまでは制御しにくいでしょう。LLMが生成したコードをレビューして、仕様を勝手に変えていないかチェックするのは非常に重要です。

## 例

- Sonnet がテスト修正をうまくできなかったため、テストの中身を `assert True` に書き換えて修正「した」ことにした。
- ある公開関数が `pass` というキーを持つ dict を返していたとき、Sonnet 3.7はTypedDictクラスで型定義しようとして文法エラーに遭遇し、解決策としてキー名を `pass_` にリネームしようとした。しかしこれはAPI仕様を破壊してしまうので、本来はできないはずの修正だった。

[[[content/blog/rule-of-three.md]]]

+++
title = "3回目の法則"
date = "2025-03-13T14:02:33-04:00"
tags = []
+++

ソフトウェア開発における「3回目の法則」は、同じコードを2回まではコピーしてよいが、3回目に同じ実装をコピーしようとしたら共通化を検討すべき、という考え方です。これは「重複をなくそう（DRY）」の単純適用よりも現実的で、2回目まではまだ抽象化方法が明確ではないことも多いからです（[The Wrong Abstraction](https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction) も参照）。

LLMはコードを重複させるのが大好きです。理由を考えると、LLMは特に指示がない場合、プログラムを変更するよう頼まれると、修正を加えた新しいプログラム全体をそのまま出力してしまうからです。重複を除去するためには、モデルがコードの重複を見つけてそれをリファクタリングする必要がありますが、主体的な思考なしにそれをやるのは難しい面があります（Sonnet 3.7は逆に不要なリファクタリングを積極的にやる傾向もありますが、「Claude Code」のシステムプロンプトを見ると、モデルには余計な修正をしすぎないようにという指示が書かれています）。また、もしコードベースにすでにコピペコードが山ほどあるなら、LLMは「あなたが望んでいるスタイル」だと判断してさらにコピペを増やすかもしれません。重複を無くしたいなら、こちらから明確に指示を出しましょう。

## 例

- ある機能のテストをLLMに書かせたら、たくさんのテストで同じコードが重複しました。ヘルパーメソッドを使ってまとめるようにLLMに明示的に依頼すると、ようやくテストを共通化してくれました。エージェントモードでファイルを分割している場合、新しいテストを書くときにヘルパーがあるファイルを読み込んでくれるかどうかも課題になります。

[[[content/blog/scientific-debugging.md]]]

+++
title = "科学的デバッグ"
date = "2025-03-09T22:18:30-04:00"
tags = []
+++

バグを直す方法として、大きく分けると「勘に頼って適当に直してみる」か、「系統立てて問題を切り分け、想定と実際の挙動のズレを特定する」の2種類があります。後者の科学的デバッグのほうが、手間はかかるかもしれませんが、一度しっかり理解すれば次に同様の問題が起きたときにも役立ちます。

推論能力が限定的なモデルは科学的手法というより「とりあえず一発で直しに行く」スタイルです。エージェントモードであれば、テストを実行して失敗すれば別のパッチを出す、というふうに試行錯誤はできますが、多くの場合は無作為に試してループに陥るだけになるでしょう。

噂では、デバッグにはより推論性能の高いモデル（Grok 3やDeepSeek-R1のようなもの）を使うとよいと言われています。個人的には、LLMにすべて任せるよりも、自分である程度原因を特定し、LLMには修正作業だけを任せるというやり方でも生産性は充分上がると感じています。「原因はここだ」と特定してあげれば、LLMはそこを修正するコードを書いてくれますし、広範囲での修正や周辺処理も併せてやってくれることがあります。

## 例

- 環境構成が壊れている（あるライブラリがインストールされていない等）状態でエージェントLLMにタスクを渡すと、状況を正しく把握できず無駄な修正を繰り返して死のループに陥ることがあります。Sonnet 3.7は特に `pip` が使えると思い込む傾向が強く、実際に `pip` が存在しない仮想環境で延々と `pip install` を試し続けるといった無意味な試行を行います。

[[[content/blog/stateless-tools.md]]]

+++
title = "ステートレスなツールを使おう"
date = "2025-03-03T21:38:09-05:00"
tags = []
+++

ツールはステートレスであるべきです。つまり、各呼び出しが他の呼び出しから独立し、呼び出し間で考慮すべき状態が存在しないのが望ましいということです。  
残念ながら、シェルは非常によく使われるツールでありながら、ローカル状態（カレントディレクトリなど）を持ち込む厄介さがあります。Sonnet 3.7は「今どのディレクトリにいるのか」を把握するのがとても苦手です。できる限り、すべてのコマンドを単一ディレクトリから実行できるようにしておくのが理想です。

本当はモデルを「ステートを変化させるツールコールは避けるようにチューニング」できるといいのですが、まだ一般的ではありません。どうしても状態が必要な場合は、モデルに常に現在の状態を明示するか、または別の仕組みで管理させる必要があるでしょう。  
ロールプレイ(RP)系コミュニティにはこのあたりの知見が豊富だと思われます。

## 例

- TypeScriptプロジェクトが「common」「backend」「frontend」という3つのサブコンポーネントに分かれており、それぞれが独立したNPMモジュールでした。プロジェクトルートからCursorを起動すると、テストを実行するためにLLMは`cd`を行おうとするのですが、どのディレクトリにいるのかをうまく把握できずに混乱します。  
  そこでフロントエンドだけをワークスペースとして開いてCursorを使うと、カレントディレクトリを気にしなくて済むので、だいぶスムーズに動きました。

[[[content/blog/stop-digging.md]]]

+++
title = "掘り進めるのをやめよう"
date = "2025-03-03T20:52:58-05:00"
tags = []
+++

今のLLMは、問題の途中で方向転換して「別の前提を先にやるべきだ」と気づいてタスクを中断する、ということが非常に苦手です。例えば「Xという機能を実装しよう」として着手した途中で、Yを先にやらないと無駄に手間がかかると気づいたとします。人間なら作業を中断して先にYを実装するでしょうが、LLMは指示されたタスク（X）をとにかく完遂しようと「掘り続けて」しまいます。  
ある意味、これは制御性を高める利点にもなりえます。モデルが勝手に「実際にはYが必要だから、そっちに変えます」と指示に反して動いてしまうほうが困るケースもあるからです。

結局、こうした事態を防ぐには最初から計画を立てるほうがよいという話になります。例えば、高度な推論のできるモデルで計画を立案し、それをコーディング用モデルに実行させるとか。また、Sonnetのエージェントモードではモデルがファイルを参照し計画を立てるので、ある程度は自律的に必要事項に気づいてくれる場合もあります。

理想的には、モデルが「これは無理筋だ」と判断できたらユーザに確認を仰ぐという流れがあればいいのですが、それを組み込みでやるには（コンテキストを多く消費してしまうなど）課題が残ります。別途「ウォッチドッグ的なLLM」を置いて検知させるなどのアイデアが考えられます。

## 例

- 乱数を使うモンテカルロシミュレーションの実装を変更したため、テストが不安定になりました。それらを通そうとLLM（Claude Code）に頼んだところ、確率的にテストが通らないことを理解できず、テスト側の条件をどんどん緩めて最終的にすべて通るようにする、という方向に進んでしまいました。「乱数生成をテスト時には固定シードにする」という本来の修正案にはたどり着けませんでした。

[[[content/blog/the-tail-wagging-the-dog.md]]]

+++
title = "しっぽが犬を振り回す"
date = "2025-03-10T10:15:50-04:00"
tags = []
+++

「しっぽが犬を振り回す (the tail wagging the dog)」とは、本来小さな要素やあまり重要でないものが、大きくて重要なものを支配してしまう状況を指します。ソフトウェア開発でも、些細な問題に囚われて本来の目的を見失うといった状況がこれに当たります。

LLMはこの問題に特に陥りやすいです。大きな原因は、一般的なチャット形式では、LLMの出力がすべて次のコンテキストに含まれてしまうということです。LLMも重要度の違いをある程度は判断できますが、あまりに多くの情報が追加されると、そもそも「最初に何をすべきだったか」を忘れてしまいがちです。  
Claude Codeではサブエージェントを用意して、グローバルなコンテキストを汚染せずにあるタスクを限定的に実行する、といった工夫がなされています。

## 例

- LLMに「とりあえず考えをまとめて」と指示したつもりが、その考えの途中で「よし、もうやってしまおう」と言い出して勝手に実行してしまう、など、途中の思考ステップをそのまま行動に移してしまうケースがあります。重要な判断を覆い隠して、意図しない方向に作業が逸れてしまうのです。

[[[content/blog/use-automatic-code-formatting.md]]]

+++
title = "自動コードフォーマットを使おう"
date = "2025-03-04T09:57:41-05:00"
tags = []
+++

gofmtやrustfmt、blackなどの自動コード整形ツールを使えば、コードベース全体を機械的にフォーマットして整合性を保つことができます。LLMは「空行にもインデントを入れるか」や「行末のスペース」などの機械的ルールを厳密に守るのは苦手です。また「行を78文字で折り返す」といった細かいスタイルにも忠実とは限りません。ですから、こうした機械的フォーマットは専門のツールで一括で行い、LLMにはもっと複雑なタスクに力を割かせたほうがいいでしょう。

これはリンターの自動修正にも同様です。自動修正が可能なリンターはそちらに任せてしまい、LLMを使うのはより高度な修正に集中させるのが効率的です。

[[[content/blog/use-mcp-servers.md]]]

+++
title = "MCPサーバを使おう"
date = "2025-03-06T11:18:04-05:00"
tags = []
+++

Model Context Protocol (MCP)サーバは、LLMが開発環境とやり取りするための標準的なインターフェースを提供するものです。CursorのエージェントモードやClaude Codeでは、この仕組みを多用しています。たとえば、RAGシステムの代わりにMCPを使って「どのファイルを読み込むか」をLLM自身に選ばせたり、テストやビルドを実行させたり、その結果を受けてさらに修正を行う、といった流れが自然に実現できます。  
AnthropicのMCPサーバは非常に便利なので、対応している場合はエージェントモードを使うとよいでしょう。

----

以下はまだ試したことのない理論的な話になりますが、

さらに進んで独自のMCPサーバを書くことはできるでしょうか？  
たとえば標準で備わっているMCPコマンドとしてシェルが利用できれば、CursorのYOLOモードのように何でもコマンドを実行できるようにできます。しかしこれは非常に危険です。任意のシェルコマンドを実行できる状態だと、LLMが環境を破壊するコマンドを実行しかねません（もちろん都度レビューすればいいのですが、現実的には大変です）。  
一方で、自分が意図する範囲のコマンドのみを実行可能なMCPサーバを用意すれば、より安全にツールを利用させることができます。しかし、2025年3月時点ではCursorがそれを柔軟に差し替える仕組みを十分に提供しているとは言えません。現状は「プラットフォーム全体で使える汎用的なMCP」を提供する方向が強く、「プロジェクト固有の `npm run` コマンド」だけをMCPサーバとして実装する、といった使い方はやや特殊な印象です。

## 例

- TypeScriptプロジェクトで型チェック (`tsc`) を実行させ、エラーが出たら直すというタスクをエージェントモードでLLMにさせる場合、MCPで実際に型チェックを実行し、その結果をモデルに返すことができます。モデルはその情報を元に、他のファイルの修正を行うかどうかを判断できます。  
  ただし、プロンプト次第ではLLMが `npm run typecheck` のようなコマンドを勝手に想像してしまう場合があるので、Cursor rulesやMCPで明示的に正しいコマンドを教えてあげるとよりスムーズに動くでしょう。

[[[content/blog/use-static-types.md]]]

+++
title = "静的型を使おう"
date = "2025-03-06T10:42:57-05:00"
tags = []
+++

動的型言語と静的型言語の選択は、プロトタイピングのしやすさとメンテナンス性のトレードオフとして昔から議論があります。LLMの台頭によって、「ボイラープレートやリファクタリングの手間が少ない言語を選ぶ」必要性は以前ほど大きくなくなりました。LLMが定型的な修正や大量のリファクタリングを自動化してくれるからです。ですから、いままでより静的型言語を優先して選択してもよいかもしれません。エージェント構成でLLMに型エラーを報告し、関連ファイルを一括修正させることも簡単になります。ただし、そのぶんトークンコストも増えるので要注意です。

しかし、学習データの主要部分がPythonとJavaScriptに偏っているため、LLMはこれらの言語を好む傾向があります。TypeScriptやPythonのtypingは「段階的型付け」であり、実際に厳格設定にするかどうかはプロジェクト次第です。LLMにも適切に指示しないと、中途半端な型定義しか付けられない場合があります。

Rustであれば、より厳格で堅牢な型システムが得られますが、Rustコード生成においてはPythonやJavaScriptほどLLMが熟知していないことが多いようです。

[[[content/blog/walking-skeleton.md]]]

+++
title = "ウォーキングスケルトン"
date = "2025-03-06T10:38:01-05:00"
tags = []
+++

[ウォーキングスケルトン](https://wiki.c2.com/?WalkingSkeleton)とは、E2Eですべてのパーツを含む、最小限の動く仕組みをまず作り上げる、というプラクティスです。欠点だらけでもいいので、まず全体を通して動く状態を手に入れてから、各部分を本格的に強化・改善していきます。スタンフォードのPhD時代にJacob Steinhardtに教わった手法ですが、今でも非常に有効だと感じています。

LLMコーディングが普及した現在、エンドツーエンドの動くものを用意するハードルは格段に下がりました。一旦最後まで通して動かしてみると、「次に何が必要か」が自明になるからです。まずは動く状態までもっていきましょう。LLMは自分で生成したコードを「自分で使う」ことはできませんが、あなたは動く実装を触って、必要な追加要件を把握したり、それをLLMに再度指示したりできます。

## 例

- 「まず全体が動く」ことを優先することで、どの部分を優先的に修正・改善すべきかが明確になります。LLMを使えば、初期段階のパイプライン構築も素早く形にできるでしょう。
